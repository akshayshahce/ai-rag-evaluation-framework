############################################################
# LLM PROVIDER CONFIGURATION
############################################################

# Options:
#   ollama   -> fully local (default)
#   openai   -> hosted OpenAI API
LLM_PROVIDER=ollama


############################################################
# EMBEDDING PROVIDER CONFIGURATION
############################################################

# Options:
#   huggingface -> local embeddings (default)
#   openai      -> hosted embeddings
EMBED_PROVIDER=huggingface


############################################################
# OLLAMA SETTINGS (LOCAL MODE)
############################################################

# Ollama server URL
OLLAMA_BASE_URL=http://localhost:11434

# Local model name
# Change if you pull another model
OLLAMA_MODEL=llama3.1:8b


############################################################
# HUGGINGFACE EMBEDDINGS (LOCAL)
############################################################

# Recommended lightweight embedding model
HF_EMBED_MODEL=intfloat/e5-small-v2


############################################################
# OPENAI SETTINGS (OPTIONAL)
############################################################

# Uncomment ONLY if using OpenAI provider

# OPENAI_API_KEY=your_openai_key_here
# OPENAI_MODEL=gpt-4o-mini
# OPENAI_EMBED_MODEL=text-embedding-3-small


############################################################
# VECTOR STORE (CHROMA)
############################################################

# Persistent storage location
CHROMA_PERSIST_DIR=chroma_db

# Must be 3â€“512 characters (Chroma requirement)
CHROMA_COLLECTION=knowledge_base


############################################################
# DATA SOURCE
############################################################

# Directory containing PDFs/text
DATA_DIR=data


############################################################
# CHUNKING STRATEGY
############################################################

CHUNK_SIZE=512
CHUNK_OVERLAP=80


############################################################
# RETRIEVAL SETTINGS
############################################################

TOP_K=4

# Limit injected context size to avoid prompt bloat
MAX_CONTEXT_CHARS=2000